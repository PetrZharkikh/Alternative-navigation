# -*- coding: utf-8 -*-
"""
Начало работы: 11.04.2023

Автор: Петросян Я.В.

Модуль содержит вспомогательные функции для вычисления геометрических трансформаций.
"""

import numpy as np
import ChislMetody
from skimage import transform
from pyquaternion import Quaternion #модуль для работы с кватернионами
import cv2 #Импорт OpenCV
import math #Модуль с математическими функциями

notDoc=['Quaternion']

def m_Projective(a,b): #Не проверялясь
    '''
Функция вычисляет матрицу проективных преобразований по координатам 4 точек.

Пространство $a$ преобразуется в пространство $b$. Данные пространства имеют
по четыре точки: a=((u0, v0), (u1, v1), (u2, v2), (u3, v3));
b=((x0, y0), (x1, y1), (x2, y2), (x3, y3))

На выходе получаем матрицу размером 3|texttimes 3, которая позволяет получить:
$b=M|cdot a$.
    '''
    m=np.array([[a[0][0], a[0][1], 1, 0, 0, 0, -a[0][0]*b[0][0], -a[0][1]*b[0][0]],
                [a[1][0], a[1][1], 1, 0, 0, 0, -a[1][0]*b[1][0], -a[1][1]*b[1][0]],
                [a[2][0], a[2][1], 1, 0, 0, 0, -a[2][0]*b[2][0], -a[2][1]*b[2][0]],
                [a[3][0], a[3][1], 1, 0, 0, 0, -a[3][0]*b[3][0], -a[3][1]*b[3][0]],
                [0, 0, 0, a[0][0], a[0][1], 1, -a[0][0]*b[0][1], -a[0][0]*b[0][1]],
                [0, 0, 0, a[1][0], a[1][1], 1, -a[1][0]*b[1][1], -a[1][0]*b[1][1]],
                [0, 0, 0, a[2][0], a[2][1], 1, -a[2][0]*b[2][1], -a[2][0]*b[2][1]],
                [0, 0, 0, a[3][0], a[3][1], 1, -a[3][0]*b[3][1], -a[3][0]*b[3][1]]])
    c=np.array([[b[0][0]],
                [b[1][0]],
                [b[2][0]],
                [b[3][0]],
                [b[0][1]],
                [b[1][1]],
                [b[2][1]],
                [b[3][1]]])
    d=np.matmul(np.linalg.inv(m),c)
    M=np.array([[d[0][0],d[3][0],d[6][0]],
                [d[1][0],d[4][0],d[7][0]],
                [d[2][0],d[5][0],1]])
    return np.transpose(M)

def cornersXY(shape, m):
    '''
Функция пересчитывает куда уйдут углы изображения в результате его
трансформации матрицей |texttt{m}.

Результатом является массив |texttt{ndarray}, в котором первая колонка
содержит пересчитанные координаты колонок углов изображения (координата $x$),
вторая колонка -- строки углов изображения (координата $y$); в строках
содержатся координаты углов: 0 -- левый-верхний угол, 1 -- правый-верхний,
2 -- левый-нижний, 3 -- правый-нижний.
    '''
    t1=np.array([[0, 0, 1],
                [shape[1], 0, 1],
                [0, shape[0], 1],
                [shape[1], shape[0], 1]]) #Массив пиксельных координат углов изображения
    t2=np.zeros((4,2))
    for i in range(4): #Вычисляем куда ушли координаты углов
        a=np.matmul(m, t1[i,:])
        a=a/a[2]
        t2[i,:]=a[0:2] #Массив содержит координаты углов после трансформации
    return t2

def calcShape(shape, m):
    '''
Вычисление размеров холста, который займет изображение размером |texttt{shape},
трансформируемое по матрице |texttt{m}.

Так как при трансформации размер изображения изменится, то бывает необходимым
вычислить размер холста $H=(w, h)$, которое займёт трансформируемое изображение.
Координаты левого-верхнего угла исходного изображения $(0, 0)$ также изменятся
и займут новое положение $t=(x, y)$.
Для того чтобы получить трансформируемое изображение на новом холсте необходимо
вычислить матрицу переноса этого изображения на новый холст $M_p$.

Результатом является кортеж из трёх элементов:
|begin{itemize}
|item $(w, h)$ -- размер нового холста;
|item $(x, y)$ -- положение верхнего-левого угла исходного изображения
      на новом холсте;
|item $M_p$ -- матрица переноса трансформированного изображения на новый холст.
|end{itemize}

Для того чтобы преобразовать исходное изображение и перенести его на новый
холст необходимо выплнить преобразование:

$$
b=m\cdot M_p\cdot a
$$
где: $a$ -- исходное изображение, $m$ -- матрица трансформации исходного
изображения (входной параметр данной функции), $M_p$ -- матрица переноса
трансформированного изображения на новый холст, $b$ -- трансформированное
изображение на новом холсте.

В этой формуле понимается, что для исходного изображения $a$ выполняется
пересчёт всех пиксел в однородной системе координат и формирование нового
изображения $b$.
    '''
    t2=cornersXY(shape, m)
    xymin=np.min(t2, axis=0)
    xymax=np.max(t2, axis=0)
    newShape=(int(np.ceil(xymax[1]-xymin[1])), int(np.ceil(xymax[0]-xymin[0])))
    newLeftUp=(t2[0,1], t2[0,0])
    reM=np.array([[1, 0, xymin[0]],
                 [0, 1, xymin[1]],
                 [0, 0, 1]])
    return (newShape, newLeftUp, reM)


def pix2M_pix(xy,m):
    '''
Функция выполняет пересчёт пиксельных координат исходного изображения в
пиксельные координаты преобразованного изображения, которое было получено
с применением матрицы трансформации $m$.

Производится умножение матрицы $m$ на вектор $t=(x, y, 1)^T$ и деление на
масштабный коэффициент. Поэтому может применяться просто как математическая
операция.

Входные данные:

|begin{itemize}
|item |texttt{xy} -- кортеж входных пиксельных координат исходного изображения
      |texttt{(x, y)}, где |texttt{x} -- координата пикселя $x$ (номер
      столбца), |texttt{y} -- координата $y$ -- (номер строки).
|item{m} -- матрица трансформации размером 3|texttimes 3.
|end{itemize}

Результат:

Кортеж пиксельных координат в том же формате что и |texttt{xy} на
преобразованном изображении, которому соответсвует указанный пиксел на
исходном изображении.
    '''
    t=np.array([[xy[0]],
                [xy[1]],
                [1]])
    r=np.matmul(m,t)
    r=r/r[2]
    return (r[0,0], r[1,0])

def m_RotCenter(angleRot, centerRot):
    '''
Вычисление матрицы трансформации для поворота изображения на угол angleRot
относительно центра вращения centerRot.

Входные данные:
    
|begin{itemize}
|item |texttt{angleRot} -- угол вращения в градусах против часовой стрелки;
|item |texttt{centerRot} -- кортеж (row, col) строка, столбец изображения,
      относительно которого произволится вращение.
|end{itemize}

Результат: матрица трансформации размером 3|texttimes 3 формата |texttt{ndarray}.
    '''
    a=np.deg2rad(angleRot)
    x=centerRot[1]
    y=centerRot[0]
    return np.array([[np.cos(a), -np.sin(a), -x*np.cos(a)+y*np.sin(a)+x],
                     [np.sin(a), np.cos(a), -x*np.sin(a)-y*np.cos(a)+y],
                     [0, 0, 1]])

def m_angle2pixel(WidthAngle,HeightAngle,Width,Height):
    '''
Вычисление матрицы пересчёта угла визирования в пиксели.
За угол визирования считаем отклонение угла от оси визирования
по ширине и высоте изображения. Центр изображения соответствует
оси визирования. Для углов принято направление координатных
осей как и в декартовой системе координат.

Входные двнные:

|begin{itemize}
|item |texttt{WidthAngle} -- угол обзора камеры по ширине;
|item |texttt{HeightAngle} -- угол обзора камеры по высоте;
|item |texttt{Width} -- ширина изображения в пикселах;
|item |texttt{Height} -- высота изображения в пикселах;
|end{itemize}

Результат:

Матрица пересчёта размером 3|texttimes 3 формата |texttt{ndarray}.
    '''
    return np.array([[Width/WidthAngle, 0, 0],
                     [0, -Height/HeightAngle, 0],
                     [Width/2, Height/2, 1]])

def distorsBPF(shape, xy, R, barrel=True):
    '''
Функция вычисляет положение пиксела на изображении с исправленной дисторсией.

Пусть есть изображение, на котором присутсьвует дисторсия с радиусом $R$ и
точка $t$ с координатами ($x$, $y$). Используя эти функцию можно рассчитать
положение точки $t$ на изображении с исправленной дисторсией, так как
геометрическое положение точек изменится.

Входные параметры:

|begin{itemize}
|item |texttt{shape} -- кортеж с размерами изображения |texttt{(width, height)};
|item |texttt{xy} -- кортеж с координатами точки $t$ |texttt{(x, y)};
|item |texttt{R} -- радиус кривизны дисторсии;
|item |texttt{barrel} -- тип дисторсии: |texttt{True} -- бочкообразная,
      |texttt{False} -- подушкообращная (по умолчанию |texttt{True}).
|end{itemize}

Результат: кортеж с координатами |texttt{(x, y)}.
    '''
    fs=np.sin if barrel else np.asin
    M2=shape[0]/2
    N2=shape[1]/2
    x=-xy[0]-N2
    y=xy[1]-M2
    l=np.sqrt(x**2+y**2)
    L=R*fs(l/R)
    dl=L-l
    dx=dl*(x/l)
    dy=dl*(y/l)
    return (xy[0]-dx,xy[1]-dy)

def distorsBP(im, R, barrel=True):
    '''
Функция испавляет дисторсию изображения.

Входные данные:

|begin{itemize}
|item |texttt{im} -- изображение в формате |texttt{ndarray, dtype=np.uint8};
|item |texttt{R} -- радиус кривизны дисторсии;
|item |texttt{barrel} -- тип дисторсии: |texttt{True} -- бочкообразная,
      |texttt{False} -- подушкообращная (по умолчанию |texttt{True}).
|end{itemize}

Результат: исправленное изображение в формате |texttt{ndarray, dtype=np.uint8}
    '''
    shape=im.shape
    D=np.sqrt(((shape[0]/2)**2)+((shape[1]/2)**2))
    if R<D:
        raise ChislMetody.ExChislMetod('Радиус не может быть меньше половины длины диагонали изображения')
    def distorsXY(xy):
        fs=np.sin if barrel else np.asin
        M=max(xy[:,1])
        N=max(xy[:,0])
        M2=M/2
        N2=N/2
        for i in xy:
            x=i[0]-N2
            y=i[1]-M2
            l=np.sqrt(x**2+y**2)
            L=R*fs(l/R)
            dl=L-l
            dx=dl*(x/l)
            dy=dl*(y/l)
            i[0]+=dx
            i[1]+=dy
        return xy
    r=transform.warp(im, distorsXY, preserve_range=True)
    return np.array(r, dtype=np.uint8)

def distorsBPR(shape,xy1,xy2,xy3,barrel=True):
    '''
Функция вычисляет радиус кривизны по кортежам |texttt{(x,y)} трёх точек,
которые должны лежать на одной прямой в исправленном изображении, но не
подчиняются этому требованию на исходном изображении.

Входные данные:

|begin{itemize}
|item |texttt{shape} -- кортеж с размерами изображения |texttt{(width, height)};
|item |texttt{xy1}, |texttt{xy2}, |texttt{xy3} -- кортежи с координатами точек
      |texttt(x, y), которые должны лежать на одной прямой в действительности,
      но из-за наличия дисторсии не подчиняются этому правилу. Например,
      мы знаем, что разметка дорожного покрытия или стена здания должны быть
      прямыми, но имеют изогнутый вид на изображении.
|item |texttt{barrel} -- тип дисторсии: |texttt{True} -- бочкообразная,
      |texttt{False} -- подушкообращная (по умолчанию |texttt{True}).
      На изображении с бочкоорбразной дисторсией прямые линии на краях
      изображения стремятся отклониться ближе к краю, при бочкообразной
      дисторсии -- напротив, к центру изображения. Вид дисторсии определяется
      визуально.
|end{itemize}

Результатом функции является скаляр |texttt{R} -- радиус дисторсии. Данный
радиус используется как входной параметр в функциях |texttt{distorsBP} и
|texttt{distorsBPF}.
    '''
    Rmin=np.sqrt(((shape[0]/2)**2)+((shape[1]/2)**2))
    Rmax=Rmin/(np.pi/180)
    def F(R):
        xy1k=distorsBPF(shape,xy1,R,barrel)
        xy2k=distorsBPF(shape,xy2,R,barrel)
        xy3k=distorsBPF(shape,xy3,R,barrel)
        return (xy1k[1]-xy2k[1])*xy3k[0]+(xy2k[0]-xy1k[0])*xy3k[1]+(xy1k[0]*xy2k[1]-xy2k[0]*xy1k[1])
    return ChislMetody.bisection(Rmin,Rmax,F,0.01)

def naklonDalnost(H, k, t):
    '''
Вычисление наклонной дальности до плоскости съёмки.

Входные параметры:
|begin{itemize}
|item |texttt{H} -- высота воздушного судна;
|item |texttt{k} -- угол крена в градусах (положительный, если левое крыло самолёта поднято вверх);
|item |texttt{t} -- угол тангажа в градусах (положительный, если нос самолёта поднят вверх).
|end{itemize}

Результат: скаляр с наклонной дальностью до плоскости съёмки.
    '''
    return H/(np.cos(np.deg2rad(k))*np.cos(np.deg2rad(t)))

def m_ProjectiveCorrect(H, k, t, f ,w ,h):
    '''
Вычисление матрицы для исправления проективнх искажений по крену и тангажу.
Матрица трансформирует изображение, при этом центральная точка (пиксел)
находится под камерой (соответсвует координатам летательного апарата в
телеметрии).

Написание функции основано на материалах статьи в файле
АлгКоррПроекИскПриМаловСъёмке.pdf.

Входные данные:
    
|begin{itemize}
|item |texttt{H} -- высота воздушного судна;
|item |texttt{k} -- угол крена в градусах (положительный, если левое крыло самолёта поднято вверх);
|item |texttt{t} -- угол тангажа в градусах (положительный, если нос самолёта поднят вверх);
|item |texttt{f} -- фокусное расстояние камеры;
|item |texttt{w} -- количество пиксел по ширине изображения;
|item |texttt{h} -- количество пиксел по высоте изображения.
|end{itemize}

Результат: матрица размером 3|texttimes 3 формата |texttt{ndarray}.
    '''
    kRk=np.deg2rad(k) #Угол крена реальной камеры в радианах
    tRk=np.deg2rad(t) #Угол тангажа реальной камеры в радианах. Оптическая ось камеры смотрит вниз.
    HVk=naklonDalnost(H, k, t) #Высота виртуальной камеры
    parRk=np.array([[f, 1, w/2],
                    [0, f, h/2],
                    [0, 0, 1]]) #Внутренние параметры реальной камеры
    parVk=parRk #Витруальная камера такая же как и реальная.
    def quatAngle(t,k): #Вычисление кватерниона поворота
      return Quaternion([np.cos(t/2)*np.cos(k/2),
                         np.cos(t/2)*np.sin(k/2),
                         np.sin(t/2)*np.sin(k/2),
                         np.sin(t/2)*np.cos(k/2)])
    qRk=quatAngle(tRk, kRk) #Кватернион поворота реальной камеры
    #qVk=quatAngle(np.deg2rad(np.deg2rad(0)), 0) #Кватернион поворота виртуальной камеры
    #qP=quatAngle(np.deg2rad(0), 0) #Кватернион поворота наблюдаемой плоскости (предполагается что она горизонтальна)
    #Кватернион поворота системы координат реальной камеры относительно виртуальной
    #q=qVk.conjugate*qP.conjugate*qRk
    #Закоментированные строки позволяют учитывать крен и тангаж виртуальной камеры и наблюдаемой поверхности, но это не проверялось.
    q=qRk#.conjugate #Разворот матрицы
    #Матрица поворота
    R=np.array([[1-2*q.y**2-2*q.z**2, 2*(q.x*q.y-q.w*q.z), 2*(q.x*q.z+q.w*q.y)],
                [2*(q.x*q.y+q.w*q.z), 1-2*q.x**2-2*q.z**2, 2*(q.y*q.z-q.w*q.x)],
                [2*(q.x*q.z-q.w*q.y), 2*(q.y*q.z+q.w*q.x), 1-2*q.x**2-2*q.y**2]])
    #Координаты точки начала системы координат реальной камеры в системе координат виртуальной камеры
    t1=np.arctan2(q.w*q.x-q.y*q.z, q.w**2+q.y**2-0.5)
    C1=np.array([0, H*np.tan(t1), HVk-H])
    T=np.matmul(-R,C1) #Вектор трансляции
    n=np.array(([[0],[0],[-1]])) #Вектор нормали к наблюдаемой поверхности
    M=np.matmul(np.matmul(parRk,(R-np.matmul(np.transpose(T),n)/HVk)), np.linalg.inv(parVk))
    return M

def m_Shivka(ima, imb):
    '''
Функция для расчёта матрицы сшивки изображений |texttt{ima} и |texttt{imb}.

Изображение |texttt{ima} считается базовым, к нему пришивается изображение
|texttt{imb}, которое необходимо трансформировать. Для его трансформации
вычисляется матрица проективных преобразований.

Входные данные: |texttt{ima}, |texttt{imb} -- изображения в формате
|texttt{ndarray, dtype=np.uint8}.

Результат: матрица размером 3|texttimes 3 формата |texttt{ndarray}.
    '''
    #Преобразуем цветные изображения в полутоновые.
    img1gray = cv2.cvtColor(ima, cv2.COLOR_BGR2GRAY)
    img2gray = cv2.cvtColor(imb, cv2.COLOR_BGR2GRAY)
    sift = cv2.xfeatures2d.SIFT_create()
    #Поиск особых точек и SIFT дескрипторов
    kp1, des1 = sift.detectAndCompute(img1gray, None)
    kp2, des2 = sift.detectAndCompute(img2gray, None)
    # FLANN parameters
    FLANN_INDEX_KDTREE = 1
    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)
    search_params = dict(checks=50)
    flann = cv2.FlannBasedMatcher(index_params, search_params)
    matches = flann.knnMatch(des1, des2, k=2)
    # Need to draw only good matches, so create a mask
    matchesMask = [[0, 0] for i in range(len(matches))]
    good = []
    pts1 = []
    pts2 = []
    # ratio test as per Lowe's paper
    for i, (m, n) in enumerate(matches):
        if m.distance < 0.7*n.distance:
            good.append(m)
            pts2.append(kp2[m.trainIdx].pt)
            pts1.append(kp1[m.queryIdx].pt)
            matchesMask[i] = [1, 0]
    rows, cols = ima.shape[:2]
    MIN_MATCH_COUNT = 10
    if len(good) > MIN_MATCH_COUNT:
        src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)
        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)
        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
    return M

def imageAzimut(shape, Mg):
    '''
Функция вычисляет азимут изображения. Азимутом изображения считается угол между
направлением на север и направлением движения вверх по изображению.

Входные данные:

|begin{itemize}
|item |texttt{shape} -- размер изображения (кортеж с количеством строк и
      столбцов);
|item |texttt{Mg} -- матрица для пересчёта пиксельных координат изображения в
      географические.
|end{itemize}

Результат: азимут изображения в радианах. Считается по часовой стрелке от
направления на север, как принято в топографии.
    '''
    t0=np.array([[shape[1]/2],
                 [shape[0]/2],
                 [1]]) #Центр изображения в однородных координатах
    tg0=np.matmul(t0,Mg) #Географические координаты центра изображения
    tg1=tg0
    tg1[0]=tg0[0]+0.1 #Координаты другой точки, которая смещена на 0.1 градус на север
    t1=np.matmul(np.linalg.inv(Mg), tg1) #Пиксельные координаты точки, смещённой на север
    tt=math.sqrt((t1[0]-t0[0])**2+(t1[1]-t0[1])**2)
    tb=math.abs(t1[1]-t0[1])
    A=math.acos(tt/tb)
    if t1[1]<t0[1]:
        if t1[0]>t1[0]:
            A=2*math.pi-A
    else:
        if t1[0]>t1[0]:
            A=math.pi+A
        else:
            A=math.pi-A
    return A
            